[
  {
    "objectID": "about/partners.html",
    "href": "about/partners.html",
    "title": "Project Partners",
    "section": "",
    "text": "Primary Partners\n\nMatthew Brook O’Donnell",
    "crumbs": [
      "Home",
      "about",
      "Project Partners"
    ]
  },
  {
    "objectID": "about/overview.html",
    "href": "about/overview.html",
    "title": "Project Overview",
    "section": "",
    "text": "The OpenText.org project is a web-based initiative to develop annotated Greek texts and tools for their analysis. The project aims both to serve, and to collaborate with, the scholarly community. Texts are annotated with various levels of linguistic information, such as text-critical, grammatical, semantic and discourse features.\nBeginning with the New Testament, the project aims to construct a representative corpus of Hellenistic Greek to facilitate linguistic and literary research of these important documents. These texts are then annotated through the addition of linguistic and literary features (including marking morphological, syntactical and discourse elements) following a comprehensive model currently under development. The resulting texts can be viewed and searched on this site. It is hoped that interested users will collaborate in the correction and enhancement of this annotation, and become involved in the annotation process themselves.\nThe key features of the project are:\n\ntexts annotated at distinct linguistic levels\nthe use of an XML encoding scheme to mark-up texts\nan ‘open’ and collaborative approach to encourage the annotation and use of texts\nan on-line tool kit to allow searching and analysis of texts",
    "crumbs": [
      "Home",
      "about",
      "Project Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to OpenText.org",
    "section": "",
    "text": "See project overview\nLearn about project partners"
  },
  {
    "objectID": "model/model-introduction.html",
    "href": "model/model-introduction.html",
    "title": "OpenText.org Annotation Model",
    "section": "",
    "text": "Introduction to the Annotation Model\n(Nov. 2004)\nThe clause is recognized as the primary building block in the OpenText.org annotation model because it is the level at which propositions are made. The different types of annotations are thus built around the clause annotation, the word group annotation (which make up the clause components), and the relationship between clauses (including the distinction into distinct primary, secondary, and secondary embedded clause levels) as the base. Table 2 summarizes the major categories of tags for the clause and word group level annotations. The vertical axis of the table delineates the four basic clause level function slots. The horizontal axis of the table gives the three clauses levels. The information within the table refers to the word groups, which fit inside the clause function slots.\n\nTable 2. Clause and Word Group Annotations\n\n\n\n\n\n\n\n\n\nClause Level\nSubject (S)\nPredicator (P)\nComplement (C)\nAdjunct (A)\n\n\n\n\nPrimary\nHead Term-Modifiers\nVerbal Form\nHead Term-Modifiers\nHead Term-Modifiers\n\n\nSecondary Unembedded\nHead Term-Modifiers\nVerbal Form\nHead Term-Modifiers\nHead Term-Modifiers\n\n\nSecondary Embedded\nHead Term-Modifiers\nVerbal Form\nHead Term-Modifiers\nHead Term-Modifiers\n\n\n\n\n\nClause Level Annotation\nAt the clause level, only four tags are used, excluding conjunctions between clauses (marked “conj”). To aid understanding, it is helpful to consider the clause functions in terms of function slots. All word groups fit into these function slots. There are only four function slots and they are:\n\nSubject (S)\nPredicator (P)\nComplement (C)\nAdjunct (A)\n\nThe tag subject (S) is used of a word group or the word groups of which something is predicated. (In traditional grammar the distinguishing term is “grammatical subject.”)\nAll verbal forms are tagged as predicators (P).\nA complement (C) is a word group or the word groups that “complete” its predicator. Common complements are direct and indirect objects.\nAn adjunct (A) is a word group or the word groups that modify the predicator, providing an indication of the circumstances associated with the process. Common adjuncts are prepositional and adverbial phrases.\nThis annotation scheme reflects Halliday’s conception of the grammar of a clause (i.e., the transitivity system at the level of a clause). The subjects and complements in the clause level annotation correspond to the participants in a process; the predicators correspond to the processes; and the adjuncts typically correspond to the circumstances associated with the process, though some adjuncts are peripheral participants in a process.\n\n\nWord Group Level Annotation Model\nAt the word group level, all words are basically either head terms or modifiers. The head term usually refers to the nominal that all the other words in the word group modify. Four types of modifiers are identified:\n\nspecifiers (sp)\ndefiners (df)\nqualifiers (ql)\nrelators (rl)\n\nA specifier (sp) is a modifier that classifies or identifies the word it modifies. Common examples of specifiers are articles and prepositions.\nA definer (df) is a modifier that attributes features or further defines the word it modifies. Common examples of definers are adjectives (both attributive and predicate structure) and appositional words or phrases.\nA qualifier (ql) is a modifier that in some way limits or constrains the scope of the word it modifies. Common examples of qualifiers are words in the genitive and dative case.\nA relator (rl) is a word specified by a preposition (i.e., the object of a preposition) that modifies another element within the word group.\n\n\nClause Levels\nClauses are divided into two levels: 1. Primary clauses 2. Secondary clauses\nThe primary and secondary distinction has to do with the two possible types of logical dependency, dependence (hypotaxis) or equality (parataxis).\nPrimary clauses are connected to each other, while secondary clauses are connected to the primary clause to which it is dependent. The majority of primary clauses consist of clauses with a finite verb.\nSecondary clauses are typically distinguished by means of a subordinating conjunction. A second type of secondary clause, the embedded clause, involves the phenomenon of rank-shifting—a linguistic element is embedded to a level of grammar lower than the typical level at which it functions. The majority of secondary embedded clauses in Greek are participial and infinitival clauses.",
    "crumbs": [
      "Home",
      "model",
      "Introduction"
    ]
  },
  {
    "objectID": "posts/gnt-copyright.html",
    "href": "posts/gnt-copyright.html",
    "title": "Can the Text of the Greek New Testament Really be Copyrighted?",
    "section": "",
    "text": "The editions of the New Testament commonly in use, such as the Nestle-Aland and UBSGNT texts, are copyrighted by various organizations. There probably is little basis for doubting that some if not much of the work that has gone into the production of these texts should be protected through copyright, especially the punctuation provided and the way in which the text-critical apparatuses that are such an important part of these texts are displayed (verse divisions, of course, pre-date copyright restrictions, since they are medieval). There are also other matters of display, such as alternation of font styles and sizes that are unique to these editions and probably merit protection as well. However, can the texts themselves be copyrighted?\nThe rough claim has been made, even by some of those connected with or the keenest advocates of the standard critical texts in use, that these texts are so close to the original text of the New Testament so as to be virtually the same as that text. If such a claim is valid (and there are many who would dispute it, however), then it would seem to indicate that the text itself of the Greek New Testament cannot and should not be copyrighted, since the text that is being presented is an ancient one, in fact one almost two thousand years old, and hence well beyond any recognizable limit on copyright.\nOthers would perhaps make the claim that the effort involved in transcribing the manuscripts merits copyright protection. That may or may not be true for a particular edition. However, those who have created the standard critical texts are not the editors of the vast majority of the texts that have been used in the compilation of their text. In fact, these standard critical texts, so far as is determinable, are dependent upon much work by earlier scholars who have transcribed these manuscripts. (The issue of whether any library or museum should control access to manuscripts, such that others are not allowed access to them for scholarly and editorial purposes is beyond the limits of comment here.)\nOthers might well pull back from the first claim above regarding the earliness of the text represented by the standard critical editions, claiming as a basis for copyright that the text is one that has been created and updated by contemporary scholars, and therefore merits protection. However, if this is true, then one must wonder what status such a text has in text-critical discussion, since a twentieth-century eclectic text that makes no claim to being early would seem to be an inferior text to a good number of earlier ones, including the major fourth century codexes. Furthermore, examination of the standard critical texts in comparison with some of the earlier manuscripts reveals very little variation at certain points. For example, let’s say that such a standard critical text of today varied in two spellings and four different word forms or phrases from Codex Sinaiticus for a book such as Philemon with 335 words. That would constitute a variance of no more than two percent. Should a difference of two percent constitute a basis for copyright? It would appear that there may be grounds for saying that New Testament Greek texts that purport to represent the earliest text, or that only vary from earlier manuscripts in relatively insignificant ways, do not merit or justify copyright protection, at least as it is usually defined."
  },
  {
    "objectID": "posts/codex-sinaiticus-as-base-text.html",
    "href": "posts/codex-sinaiticus-as-base-text.html",
    "title": "Using Codex Sinaiticus as an Alternative to a Modern Eclectic Text",
    "section": "",
    "text": "Codex Sinaiticus was discovered in the nineteenth century by Constantine Tischendorf at St Catherine’s Monastery in the Sinai. He realized from the outset that this manuscript was one of the most important New Testament manuscripts ever discovered. His judgment at that time has proven correct. Despite the controversy that has surrounded this manuscript ever since, one fact is clear-it constitutes one of the two earliest major majuscule codex manuscripts used in textual criticism of the New Testament. In fact, Sinaiticus is the only one of these two codexes, the other being Codex Vaticanus, to be complete for the New Testament. The fourth-century date assigned to Sinaiticus and Vaticanus has suggested to many that these may have been two of the codex manuscripts reportedly prepared by Eusebeius for Constantine.\nIn any case, the general quality of the manuscripts, their completeness and their early date have given them a position of priority in text-critical circles from the time of Westcott and Hort to the present. Westcott and Hort labelled them the Neutral Text, and whereas few textual critics would use such language today, these two manuscripts still maintain a position of supreme importance. Examination of subsequent editions that put emphasis upon the Alexandrian textual tradition, such as the Nestle-Aland or UBSGNT text, shows that Sinaiticus and Vaticanus still reign supreme. Despite much discussion of the New Testament Greek papyri, many of them fairly recently discovered and published, their importance for New Testament textual criticism has not eclipsed the significance of the two major codexes. In fact, the departures by modern so-called eclectic Greek texts from these major codexes are often few in number in a given New Testament book, sometimes confined for the most part to variations in spelling.\nIn the light of this, it is worth considering whether there should not be a return to use of such a text as Codex Sinaiticus. Rather than being a scholarly construct of the twentieth century, Codex Sinaiticus, along with other ancient manuscripts, constituted an ancient manuscript actually used and revised by various early Christian communities (the various correcting hands of Sinaiticus attest to its use, but also raise a number of important critical issues). Therefore, it provides unparalleled access to an earlier form of the text as used by early Christians. The text of Sinaiticus constitutes the basis for the texts used in OpenText.org."
  },
  {
    "objectID": "posts/why-opentext-org.html",
    "href": "posts/why-opentext-org.html",
    "title": "Why OpenText.org?",
    "section": "",
    "text": "First-time visitors to this website may be wondering: What is the nature and purpose of this website? Why does OpenText.org exist? There are really several levels of motivations & several different kinds of issues our project is trying to address. One way of to answer this question is to summarize the purposes of the OpenText.org project under 4 headings:\n\nto address limitations of existing morphological texts\nto address limitations of traditional grammar\nto address limitations of traditional methods of studying texts, grammar, and lexis\nto provide material necessary for thorough discourse analysis & exegetical study\n\nFirst, we are trying to address the limitations of existing morphological texts. We realize that there are already some very fine texts in available software programs. Nevertheless, they are all strictly word-based, that is the information available is restricted to the morphology and meaning of individual words. Thus they are of limited help when our interest is in the patterns and meanings of constructions above the word-level such as phrases, clauses, and paragraphs. Currently, the word group and clause level annotations of OpenText.org provide previously-unavailable information on phrase and clause level patterns and meanings.\nSecond, we are trying to address the limitations of traditional grammar. We have a proud tradition of grammars and we literally stand on the shoulder of giants when we conduct studies on Greek grammar. We are by no means suggesting that we should start from scratch. Nevertheless, the major reference grammars are significantly dated and do not take into account the more complete textual evidence we now possess or insights from at least half a century of linguistic studies. By applying corpus linguistics, OpenText.org incorporates insights from modern linguistics and uses the considerable power of modern computers to provide comprehensive searches and displays of all available information on word, word group, and clause level grammatical and semantic phenomena. For those interested in learning Greek or in teaching Greek in a more effective manner, our levels of annotation also contain a basic framework for understanding Greek grammar that we believe is both easier to learn and sounder linguistically than what is often found in pedagogical grammars currently available (e.g., there is a confused mixing of formal and semantic labels and an unjustifiable multiplying of such labels for grammatical constructions like dozens of categories for the genitive construction).\nThird, we are trying to address the limitations of traditional methods of studying texts, grammar, and lexis. The word, word group, and clause information furnished by OpenText.org is designed to aid those studying texts, grammar, and/or lexis get comprehensive and reliable results in a time-efficient manner (e.g., getting complete evidence in seconds or minutes that may have taken weeks or months previously by manual counting). Besides help in overcoming previous limitations on comprehensiveness and time, the model and information supplied by our project is put forward as a starting point for further studies and discussions on what are effective methods of studying texts, grammar, and lexis. From our perspective, an effective method must be based on sound linguistic principles and we are unapologetic in commending the linguistic model upon which our project is built.\nFourth, we are trying to provide material necessary for thorough discourse analysis and exegetical study. As modern linguistic theory and studies have shown, studies focused mainly on words are inadequate and unable to provide thorough insight into the patterns and meanings of an entire discourse/text or even any given stretch of text. In New Testament studies, there is apparently increasing interest in analyzing entire discourses and in various methods of discourse analysis. With the OpenText.org project, we provide both a theory and a means of application of discourse analysis in our searchable and reusable texts. It is our hope that our work will not only aid many in doing thorough discourse analyses and exegetical studies, but also spur further discussion on and research into how to do discourse analysis and exegetical study in sounder and more effective ways."
  },
  {
    "objectID": "posts/opentextorg-from-a-pedagogical-perspective.html",
    "href": "posts/opentextorg-from-a-pedagogical-perspective.html",
    "title": "Introduction to the OpenText.org Annotation Model from a Pedagogical Perspective",
    "section": "",
    "text": "Imagine that you’re teaching an introductory class on the Gospels to university students. You have six weeks to instruct them how to read the Gospels, on top of educating them about the content of these writings, introductory issues, and other matters. Most of your students know practically nothing about the Gospels and don’t have the slightest idea how to read them. What kind of approach would you take to instruct them?\nI faced this situation when I taught my first class on the Synoptic Gospels. Having just applied M. A. K. Halliday’s model of systematic functional linguistics (SFL) to my study of “law” in Paul’s epistle to the Romans in my dissertation, I decided to take up the challenge of teaching uninitiated students how to apply aspects of this model to the study of the Gospels.\nThe first challenge was to boil down the theory into a simplified framework that my students could readily understand and learn. I explained that there are 3 components common to all linguistic representation:\n\nThe participants (the who & whom)\nThe process (what is happening or done)\nThe circumstances (when, where, how, why)\n\nUsing this system of “transitivity,” we represent through language who is doing what to/for whom under what kind of circumstances. The meanings represented can in turn be categorized under three main functions, answering the following three questions:\n\nWhat? (i.e., what is happening?)\nWho? (i.e., what roles are the participants playing?)\nHow? (i.e., how does what is happening and what roles the participants are playing fit together and cohere as a message?)\n\nSome students were able to apply the framework to read the Gospel texts without further assistance. The majority, however, remained unsure how to put the framework to use. My second challenge, then, was to present my students with a model to systematically ask and answer the questions concerning the participants, process, and circumstances and how everything coheres as a message. I prepared the following template to help them. First, I told them to use existing paragraph divisions and titles in their English Bibles as a starting point. Then, I taught them to ask the following two-part questions in sequence:\n\nWho are the main participants in the paragraph?; and how do you determine that those participants are the main ones?\nWhat are the role relationships between those participants? and how do you determine the role relationships between those participants?\nWhat are the main processes?; and how do you determine that those processes are the main ones?\n\nFinally, I instructed them to ask if there are any other words or ideas that are emphasized before painting an overall portrait of the passage with the answers they have given above. The first two-part question gets the students to trace the interaction of both the external participants (i.e., writer and audience) and internal participants (i.e., characters in the narrative or exposition). Participants that get the most press usually correspond to the main participants. The second two-part question leads the students to look further at descriptions of those participants and who is doing what to/for whom. The third two-part question focuses on what is happening. The main processes are usually repeated—either with the same or related words. While prominent participants and processes are picked up in the previous questions, possibly emphasized circumstances are taken into consideration in the final question before painting an overall portrait.\nWhat were the results of this experiment with teaching how to read a text using a simplified systemic functional framework? In an anonymous survey I conducted 4 weeks into the class, 11 out of 22 students rated the model as excellent and 3 others rated it as good. In the final two weeks of the class, I devoted much effort to clearing up the remaining confusion that some students had and gave the class more practice applying the model. In the section on text analysis on the final exam, 13 out of 22 students achieved 90% or above accuracy in answering questions on the various Gospel passages on which they were tested. Another 6 students scored 80% or above.\nWhat lessons may we learn from my teaching experience above? First, the basic concepts underlying systemic functional linguistics can, in fact, be readily understood and learned. Second, the SFL framework can help any would-be interpreter in the task of reading and understanding a biblical text like a Gospel passage.\nEven though the annotation model that you will be introduced to on this website is more sophisticated and technically rigorous, the basic concepts and questions remain the same as what I taught my students. The different levels of annotation play a role in answering each of these questions. For example, the clause level annotation elegantly captures who does what to/for whom under what circumstances in terms of the labels Subject (S), Predicator (P), Complement (C), and Adjunct (A). The participant referent annotation traces the interaction of the external and internal participants. The semantic domain annotation allows for the analysis of patterns of meaning repetition and thus discernment of prominent fields of meaning (i.e., what processes or circumstances are emphasized)."
  },
  {
    "objectID": "model/guidelines.html",
    "href": "model/guidelines.html",
    "title": "OpenText.org Annotation Model Specifications & Guidelines",
    "section": "",
    "text": "Current specifications\n\nCharacter Level (Diplomatic) Papyrus Encoding (ver. 0.1)\nBase (Word) Level Annotation Specification (ver. 0.2)\nWord Group Annotation Specification (ver. 0.2)\nClause Level Annotation Specification (ver. 0.2)\nParagraph Level Annotation Specification (ver. 0.2)\n\n\n\nOlder Specifications:\n\nWord Group Annotation Specification (ver. 0.1)\nClause Level Annotation Specification (ver. 0.1)",
    "crumbs": [
      "Home",
      "model",
      "Guidelines"
    ]
  },
  {
    "objectID": "about/rationale.html",
    "href": "about/rationale.html",
    "title": "Rationale for OpenText.org",
    "section": "",
    "text": "What is the rationale for undertaking Opentext.org as a project? In a nutshell, Opentext.org is a web-based initiative to provide an annotated corpus of Greek texts and tools for their analysis. The long term goal of the project is to construct a representative corpus of Hellenistic Greek (including the entire New Testament and selected Hellenistic writings of the same period) to facilitate linguistic and literary research of the New Testament documents. For most of our users, this succinct answer may need further expansion and clarification. We may do this by answering the following two questions.\n\nWhat Is a Corpus?\nFirst, “What is a corpus and is there a distinction between a text and a corpus?” A text is basically a written discourse that is considered a unit. For instance, the epistle to the Romans is a text, and so are the Gospel of John and the third epistle of John. A corpus, however, is not simply a collection of texts. A corpus “seeks to represent a language or some part of a language.” Thus, a corpus consists of an intentional grouping of particular texts, according to specific criteria. For example, one could collect a corpus of the sayings of Jesus or of the letters attributed to Peter. There is no reason why all the New Testament texts or any combination of the New Testament texts cannot be considered a corpus. As used here, a corpus is “a finite-sized body of machine-readable text, sampled in order to be maximally representative of the language variety under consideration.” To make it machine-readable, the Greek text of the New Testament is encoded in Extensible Markup Language (XML), which is designed to clearly label data and enable its users to access, manipulate, and repackage that data with ease.\n\n\nWhat Are the Characteristics of Corpus-Based Analysis?\nThe essential characteristics of corpus-based analysis are as follows:\n\nit is empirical, analyzing the actual patterns of use in natural texts;\nit utilizes a large and principled collection of natural texts, known as a “corpus,” as the basis for analysis;\nit makes extensive use of computers for analysis, using both automatic and interactive techniques;\nit depends on both quantitative and qualitative analytical techniques.\n\nThese characteristics lead to at least four advantages in using a corpus-based approach in studies of language use. First, computers can handle large amounts of language and keep track of many contextual factors simultaneously. Second, actual language usage in the corpus (not just a theoretical construct) is the object of analysis. Third, computer-assisted analysis facilitates the accounting of the extent to which a pattern is found and of contextual factors that influence variability. Fourth, by means of the data-handling capability of computers many previously unfeasible research questions can be asked.",
    "crumbs": [
      "Home",
      "about",
      "Rationale for OpenText.org"
    ]
  },
  {
    "objectID": "about/contact.html",
    "href": "about/contact.html",
    "title": "Contact & Involvement",
    "section": "",
    "text": "Contributing to the Annotation\nIf you are interested in getting involved in the annotation of the Greek New Testament, Apostolic Fathers and other Hellenistic texts please contact Matt O’Donnell.\n\nEmail\nFor information regarding OpenText.org please contact Matt O’Donnell",
    "crumbs": [
      "Home",
      "about",
      "Contact & Involvement"
    ]
  }
]